{"cells":[{"cell_type":"markdown","id":"94f4bdbd","metadata":{"id":"94f4bdbd"},"source":["# Model: AdaBoost (Decision Tree)"]},{"cell_type":"markdown","id":"114b0911","metadata":{"id":"114b0911"},"source":["# "]},{"cell_type":"code","execution_count":13,"id":"64881926","metadata":{"executionInfo":{"elapsed":62,"status":"ok","timestamp":1680618681249,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"64881926"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statistics\n","import plotly.express as px\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from sklearn.feature_selection import RFE\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import uniform\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#Libraries for data pre-processing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn import preprocessing\n","from sklearn.model_selection import GridSearchCV\n","\n","#For Decision Tree implementation\n","from scipy.stats import entropy\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","\n","#For KNN implementation\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#For Bagging implementation\n","from sklearn.ensemble import BaggingClassifier\n","\n","#For AdaBoost implementation\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.naive_bayes import GaussianNB\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.feature_selection import RFECV\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import uniform\n","from sklearn import tree\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, roc_curve\n","import statistics"]},{"cell_type":"code","execution_count":14,"id":"cc79fe67","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":62,"status":"error","timestamp":1680618681250,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"cc79fe67","outputId":"3725648d-c236-4f16-df08-8ae6775afc19"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-0daa80fa022d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read from CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleaned_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleaned_data.csv'"]}],"source":["# Read from CSV file\n","df = pd.read_csv('Data/cleaned_data.csv')"]},{"cell_type":"markdown","id":"cb47bb46","metadata":{"id":"cb47bb46"},"source":["<hr>\n","\n","### Splitting of Data Set\n","- Total records: 70692\n","- Validation Set: 13% (9190 records)\n","- Unseen Set: 4% (2830 Records)\n","- Training and Test set: 83% (58672 Records)"]},{"cell_type":"code","execution_count":null,"id":"8ac58b15","metadata":{"executionInfo":{"elapsed":58,"status":"aborted","timestamp":1680618681251,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"8ac58b15"},"outputs":[],"source":["X = df.drop('Diabetes_binary', axis=1) # features\n","y = df['Diabetes_binary']\n","\n","# Split the dataset into training and test sets\n","training_set, test_set, y_train, test_labels = train_test_split(X, y, test_size=0.13, random_state=424, shuffle=True)\n","\n","# Split the training set into validation and remaining training sets\n","training_set, validation_set, y_train, validation_labels = train_test_split(training_set, y_train, test_size=0.1131, random_state=424, shuffle=True)\n","\n","# Split the remaining training set into an unseen set\n","training_set, unseen_set, train_labels, unseen_labels = train_test_split(training_set, y_train, test_size=0.0296, random_state=424, shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"id":"82d8e06c","metadata":{"executionInfo":{"elapsed":59,"status":"aborted","timestamp":1680618681252,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"82d8e06c"},"outputs":[],"source":["remaining_data, val_data = train_test_split(df, test_size=0.13, random_state=424, shuffle=True)\n","print(df.shape)\n","print(val_data.shape)\n","\n","train_test_data, unseen_data = train_test_split(remaining_data, test_size=0.046, random_state=424, shuffle=True)\n","print(unseen_data.shape)\n","print(train_test_data.shape)"]},{"cell_type":"code","execution_count":null,"id":"4749ef5d","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681253,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"4749ef5d"},"outputs":[],"source":["train_test_data.head()"]},{"cell_type":"code","execution_count":null,"id":"fe929d36","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681253,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"fe929d36"},"outputs":[],"source":["val_data.head()"]},{"cell_type":"markdown","id":"7d7c0681","metadata":{"id":"7d7c0681"},"source":["- training_set : train_labels\n","- test_set : test_labels\n","- validation_set : validation_labels\n","- unseen_set : unseen_labels\n","\n","<hr>\n","<hr>"]},{"cell_type":"markdown","id":"b1713b64","metadata":{"id":"b1713b64"},"source":["### Correlation Coefficient Results\n","This variables have more correlated with the target variable Diabetes_binary - Greater than 0.25\n","- Diabetes_binary and HighBP have a correlation coefficient of 0.3815155489073117\n","- Diabetes_binary and HighChol have a correlation coefficient of 0.28921280708865016\n","- Diabetes_binary and BMI have a correlation coefficient of 0.29337274476103575\n","- Diabetes_binary and GenHlth have a correlation coefficient of 0.4076115984949182\n","- Diabetes_binary and DiffWalk have a correlation coefficient of 0.272646006159808\n","- Diabetes_binary and Age have a correlation coefficient of 0.27873806628188813\n","- Diabetes_binary and BMI_bins have a correlation coefficient of 0.2995782127672782"]},{"cell_type":"markdown","id":"71f599be","metadata":{"id":"71f599be"},"source":["<hr>"]},{"cell_type":"markdown","id":"7cf9f2e9","metadata":{"id":"7cf9f2e9"},"source":["### Model Evaluation\n","\n","##### Variables Used : Top 6 variables based on <u>Correlation Cofficient</u>\n","['HighBP', 'HighChol', 'GenHlth', 'DiffWalk', 'Age','BMI_bins']\n"]},{"cell_type":"code","execution_count":null,"id":"1f3a6660","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681254,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"1f3a6660"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n"]},{"cell_type":"code","execution_count":null,"id":"b34601b1","metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1680618681255,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"b34601b1"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'HighChol', 'GenHlth', 'DiffWalk', 'Age','BMI_bins']\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"048ce250","metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1680618681255,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"048ce250"},"outputs":[],"source":["# Create adaboost model object\n","\n","adaboost_model = AdaBoostClassifier()\n"]},{"cell_type":"code","execution_count":15,"id":"0cd482db","metadata":{"executionInfo":{"elapsed":61,"status":"ok","timestamp":1680618681256,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"0cd482db"},"outputs":[],"source":["# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n"]},{"cell_type":"code","execution_count":16,"id":"185b14be","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"executionInfo":{"elapsed":61,"status":"error","timestamp":1680618681257,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"185b14be","outputId":"b29d7a88-f4de-436d-e52e-a3bd0347775d"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-71347cee173f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Extract the training and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]},{"data":{"text/plain":["<Figure size 1000x1000 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')"]},{"cell_type":"markdown","id":"15c0de06","metadata":{"id":"15c0de06"},"source":["##### Average AUC-ROC Curve of all folds\n","The AUC score ranges from 0 to 1, where 0 indicates that the model is predicting all negative cases as positive and 1 indicates that the model is predicting all positive cases as positive. A score of 0.5 indicates that the model is performing no better than random guessing, and a score of 1 indicates that the model is making perfect predictions."]},{"cell_type":"code","execution_count":null,"id":"11f5979b","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681258,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"11f5979b"},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"68693571","metadata":{"executionInfo":{"elapsed":59,"status":"aborted","timestamp":1680618681258,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"68693571"},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"markdown","id":"a4c19a6f","metadata":{"id":"a4c19a6f"},"source":["##### Confusion Matrix\n","Using the values from confusion matrix, we can easily extract the following:\n","- True Positives (TP): we correctly predicted that they do have diabetes\n","- True Negatives (TN): we correctly predicted that they don't have diabetes\n","- False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\")\n","- False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\")\n","\n","##### Metrics from Confusion Matrix\n","Using the values derived from the confusion matrix, we can then calculate the following:\n","- Classification Accuracy -> how often is the classifier correct?\n","- Classification Error -> how often is the classifier incorrect?\n","- Sensitivity -> When the actual value is positive, how often is the prediction correct?\n","- Specificity -> When the actual value is negative, how often is the prediction correct?\n","- Precision -> When a positive value is predicted, how often is the prediction correct?\n","- F1 Score "]},{"cell_type":"code","execution_count":null,"id":"a7a7d04b","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681259,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"a7a7d04b"},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"b79c4a0a","metadata":{"id":"b79c4a0a"},"source":["<hr>\n","<hr>"]},{"cell_type":"markdown","id":"592c2b7c","metadata":{"id":"592c2b7c"},"source":["## Feature selection\n","### Method 1: Recursive Feature Elimination with Cross-Validation\n"," It is a feature selection algorithm that combines both recursive feature elimination (RFE) and cross-validation (CV) techniques to identify the optimal subset of features for a given predictive model.\n"," \n","It works by recursively removing features from the original feature set and training a model on the remaining features until a specified number of features is reached. At each iteration, the algorithm uses cross-validation to estimate the performance of the model and decides which feature to eliminate based on its contribution to the model's performance."]},{"cell_type":"code","execution_count":null,"id":"635b9eb2","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681259,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"635b9eb2"},"outputs":[],"source":["from sklearn.feature_selection import RFECV\n","\n","X = train_test_data[['HighBP', 'HighChol', 'CholCheck', 'Smoker',\n","       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n","       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n","       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income',\n","       'BMI_bins']]\n","y = train_test_data[\"Diabetes_binary\"]\n","\n","# Create a CatBoost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the CatBoost model and number of features to select\n","rfecv = RFECV(model, cv=5, scoring='f1_weighted')\n","\n","# Fit the RFE object on your dataset\n","rfecv.fit(X, y)\n","\n","print(\"Feature ranking: \", rfecv.ranking_)\n","\n","# Get the names of the optimal features\n","RFECV_selected = []\n","for index in range(len(X.columns)):\n","    if rfecv.ranking_[index] == 1:\n","        RFECV_selected.append(X.columns[index])\n","\n","RFECV_selected\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ca6201b9","metadata":{"executionInfo":{"elapsed":60,"status":"aborted","timestamp":1680618681260,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"ca6201b9"},"outputs":[],"source":["selected_features_indices = np.where(rfecv.support_ == True)[0]\n","selected_features = X.columns[selected_features_indices]\n","print(\"Selected features:\", selected_features)"]},{"cell_type":"code","execution_count":null,"id":"fdb2adf6","metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1680618681261,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"fdb2adf6"},"outputs":[],"source":["n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n","plt.figure()\n","plt.xlabel(\"Number of features selected\")\n","plt.ylabel(\"Mean test accuracy\")\n","plt.errorbar(\n","    range(1, n_scores + 1),\n","    rfecv.cv_results_[\"mean_test_score\"],\n","    yerr=rfecv.cv_results_[\"std_test_score\"],\n",")\n","plt.xticks(range(1,22))\n","plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n","plt.show()"]},{"cell_type":"markdown","id":"57bbc3f6","metadata":{"id":"57bbc3f6"},"source":["##### RFECV Evaluation\n","Based on RFECV, almost all variables variables are ranked 1. ['HighBP',\n"," 'HighChol',\n"," 'CholCheck',\n"," 'Smoker',\n"," 'Stroke',\n"," 'HeartDiseaseorAttack',\n"," 'PhysActivity',\n"," 'Veggies',\n"," 'HvyAlcoholConsump',\n"," 'GenHlth',\n"," 'MentHlth',\n"," 'PhysHlth',\n"," 'DiffWalk',\n"," 'Sex',\n"," 'Age',\n"," 'Education',\n"," 'Income',\n"," 'BMI_bins']\n","\n","\n","But after plotting the mean accuracy against the number of features selected, we can see that it plateaus at <u><b>5 features</b></u>\n","<br>\n","<b>Optimal Number of features: 5 </b>"]},{"cell_type":"markdown","id":"8887ff56","metadata":{"id":"8887ff56"},"source":["### Method 2: Recursive Feature Elimination\n","It is a feature selection algorithm that selects the most important features from a given dataset by recursively eliminating less important features.\n","\n","The RFE algorithm works by first training a model on the entire feature set and ranking the features based on their importance. It then eliminates the least important feature from the set and repeats the process of training and ranking until a specified number of features is reached. At each iteration, the algorithm evaluates the performance of the model using the remaining features and decides which feature to eliminate based on its contribution to the model's performance."]},{"cell_type":"code","execution_count":null,"id":"d41ff7ba","metadata":{"executionInfo":{"elapsed":61,"status":"aborted","timestamp":1680618681261,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"d41ff7ba"},"outputs":[],"source":["X = train_test_data[['HighBP','HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack','PhysActivity','Veggies','HvyAlcoholConsump','GenHlth','MentHlth','PhysHlth','DiffWalk','Sex','Age','Education','Income','BMI_bins']]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"markdown","id":"2e86aaa2","metadata":{"id":"2e86aaa2"},"source":["##### Select 5 Features"]},{"cell_type":"code","execution_count":null,"id":"67ecb04b","metadata":{"executionInfo":{"elapsed":62,"status":"aborted","timestamp":1680618681262,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"67ecb04b"},"outputs":[],"source":["# Create a Adaboost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the Adaboost model and number of features to select\n","rfe = RFE(model, n_features_to_select=5)\n","\n","# Fit the RFE object on your dataset\n","fit = rfe.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"0e3abcf3","metadata":{"executionInfo":{"elapsed":62,"status":"aborted","timestamp":1680618681263,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"0e3abcf3"},"outputs":[],"source":["# Get the selected features\n","selected_features = X.columns[rfe.support_]\n","\n","print(\"Num Features: %d\" % rfe.n_features_)\n","print(\"Selected Features: %s\" % rfe.support_)\n","print(\"Selected Features: %s\" % selected_features)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"]},{"cell_type":"markdown","id":"58fbcdd5","metadata":{"id":"58fbcdd5"},"source":["##### Select 6 Features"]},{"cell_type":"code","execution_count":null,"id":"b1b8705f","metadata":{"executionInfo":{"elapsed":62,"status":"aborted","timestamp":1680618681263,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"b1b8705f"},"outputs":[],"source":["# Create a Adaboost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the Adaboost model and number of features to select\n","rfe = RFE(model, n_features_to_select=6)\n","\n","# Fit the RFE object on your dataset\n","fit = rfe.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"98b3c533","metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1680618681264,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"98b3c533"},"outputs":[],"source":["# Get the selected features\n","selected_features = X.columns[rfe.support_]\n","\n","print(\"Num Features: %d\" % rfe.n_features_)\n","print(\"Selected Features: %s\" % rfe.support_)\n","print(\"Selected Features: %s\" % selected_features)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"]},{"cell_type":"markdown","id":"d14eebc5","metadata":{"id":"d14eebc5"},"source":["##### Select 7 Features"]},{"cell_type":"code","execution_count":null,"id":"f2556c85","metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1680618681264,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"f2556c85"},"outputs":[],"source":["# Create a Adaboost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the Adaboost model and number of features to select\n","rfe = RFE(model, n_features_to_select=7)\n","\n","# Fit the RFE object on your dataset\n","fit = rfe.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"4fef9052","metadata":{"executionInfo":{"elapsed":63,"status":"aborted","timestamp":1680618681265,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"4fef9052"},"outputs":[],"source":["# Get the selected features\n","selected_features = X.columns[rfe.support_]\n","\n","print(\"Num Features: %d\" % rfe.n_features_)\n","print(\"Selected Features: %s\" % rfe.support_)\n","print(\"Selected Features: %s\" % selected_features)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"]},{"cell_type":"markdown","id":"638a5120","metadata":{"id":"638a5120"},"source":["##### Select 8 Features"]},{"cell_type":"code","execution_count":null,"id":"64a75196","metadata":{"executionInfo":{"elapsed":64,"status":"aborted","timestamp":1680618681266,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"64a75196"},"outputs":[],"source":["# Create a Adaboost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the Adaboost model and number of features to select\n","rfe = RFE(model, n_features_to_select=8)\n","\n","# Fit the RFE object on your dataset\n","fit = rfe.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"afa130c5","metadata":{"executionInfo":{"elapsed":64,"status":"aborted","timestamp":1680618681266,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"afa130c5"},"outputs":[],"source":["# Get the selected features\n","selected_features = X.columns[rfe.support_]\n","\n","print(\"Num Features: %d\" % rfe.n_features_)\n","print(\"Selected Features: %s\" % rfe.support_)\n","print(\"Selected Features: %s\" % selected_features)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"]},{"cell_type":"markdown","id":"ed8c05fd","metadata":{"id":"ed8c05fd"},"source":["##### Select 18 Features"]},{"cell_type":"code","execution_count":null,"id":"1be24a0c","metadata":{"executionInfo":{"elapsed":64,"status":"aborted","timestamp":1680618681267,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"1be24a0c"},"outputs":[],"source":["# Create a Adaboost classifier model\n","model = AdaBoostClassifier()\n","\n","# Create an RFE object with the Adaboost model and number of features to select\n","rfe = RFE(model, n_features_to_select=18)\n","\n","# Fit the RFE object on your dataset\n","fit = rfe.fit(X, y)"]},{"cell_type":"code","execution_count":null,"id":"2c468cf6","metadata":{"executionInfo":{"elapsed":65,"status":"aborted","timestamp":1680618681268,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"2c468cf6"},"outputs":[],"source":["# Get the selected features\n","selected_features = X.columns[rfe.support_]\n","\n","print(\"Num Features: %d\" % rfe.n_features_)\n","print(\"Selected Features: %s\" % rfe.support_)\n","print(\"Selected Features: %s\" % selected_features)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"]},{"cell_type":"markdown","id":"87070dd4","metadata":{"id":"87070dd4"},"source":["<hr>\n","<hr>\n","\n","## After Feature Selection methods\n","\n","\n","### Model Evaluation 2\n","\n","##### Variables Used : \n","Based on RFECV, <b>Optimal number of features: 5</b>\n","<br>\n","Based on RFE\n","<br>\n","Selected Num Features: 5 - ['HighBP', 'GenHlth', 'Age', 'Income', 'BMI_bins']\n"]},{"cell_type":"code","execution_count":null,"id":"e656e300","metadata":{"executionInfo":{"elapsed":65,"status":"aborted","timestamp":1680618681268,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"e656e300"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'GenHlth', 'Age', 'Income', 'BMI_bins']\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"694000d2","metadata":{"executionInfo":{"elapsed":66,"status":"aborted","timestamp":1680618681269,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"694000d2"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n","\n","\n","# Create ___ model object\n","\n","adaboost_model = AdaBoostClassifier()\n","\n","\n","# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n","\n","plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n"]},{"cell_type":"markdown","id":"f761c851","metadata":{"id":"f761c851"},"source":["##### Average AUC-ROC Curve of all folds"]},{"cell_type":"code","execution_count":null,"id":"68248097","metadata":{"executionInfo":{"elapsed":65,"status":"aborted","timestamp":1680618681269,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"68248097","scrolled":true},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"fe00e481","metadata":{"executionInfo":{"elapsed":66,"status":"aborted","timestamp":1680618681270,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"fe00e481"},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"f5b37907","metadata":{"executionInfo":{"elapsed":66,"status":"aborted","timestamp":1680618681270,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"f5b37907","scrolled":true},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"913f63a5","metadata":{"id":"913f63a5"},"source":["<hr>\n","\n","### Model Evaluation 3\n","\n","##### Variables Used : \n","Based fully on RFECV\n","<br>\n","Selected Num Features: 6 - ['HighBP', 'GenHlth', 'Age', 'Education', 'Income', 'BMI_bins']\n"]},{"cell_type":"code","execution_count":null,"id":"d0ce2bb9","metadata":{"executionInfo":{"elapsed":67,"status":"aborted","timestamp":1680618681271,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"d0ce2bb9"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'GenHlth', 'Age', 'Education', 'Income', 'BMI_bins']\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"333f459d","metadata":{"executionInfo":{"elapsed":67,"status":"aborted","timestamp":1680618681271,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"333f459d"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n","\n","\n","# Create adaboost model object\n","\n","adaboost_model = AdaBoostClassifier()\n","\n","\n","# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n","\n","plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n"]},{"cell_type":"markdown","id":"2475b12e","metadata":{"id":"2475b12e"},"source":["##### Average AUC-ROC Curve of all folds"]},{"cell_type":"code","execution_count":null,"id":"8b7d717b","metadata":{"executionInfo":{"elapsed":68,"status":"aborted","timestamp":1680618681272,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"8b7d717b","scrolled":true},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"12fdd3e7","metadata":{"executionInfo":{"elapsed":67,"status":"aborted","timestamp":1680618681272,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"12fdd3e7"},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"94fabcf4","metadata":{"executionInfo":{"elapsed":68,"status":"aborted","timestamp":1680618681273,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"94fabcf4"},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"52b8f8b2","metadata":{"id":"52b8f8b2"},"source":["<hr>\n","\n","### Model Evaluation 4\n","\n","##### Variables Used : \n","Based fully on RFECV\n","<br>\n","Selected Num Features: 7 - ['HighBP', 'GenHlth', 'Sex', 'Age', 'Education', 'Income', 'BMI_bins']"]},{"cell_type":"code","execution_count":null,"id":"0d4bd5ab","metadata":{"executionInfo":{"elapsed":68,"status":"aborted","timestamp":1680618681273,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"0d4bd5ab"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'GenHlth', 'Sex', 'Age', 'Education', 'Income', 'BMI_bins']\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"95aad618","metadata":{"executionInfo":{"elapsed":69,"status":"aborted","timestamp":1680618681274,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"95aad618"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n","\n","\n","# Create adaboost model object\n","\n","adaboost_model = AdaBoostClassifier()\n","\n","\n","# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n","\n","plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n"]},{"cell_type":"markdown","id":"4c0e9091","metadata":{"id":"4c0e9091"},"source":["##### Average AUC-ROC Curve of all folds"]},{"cell_type":"code","execution_count":null,"id":"5df02e6a","metadata":{"executionInfo":{"elapsed":70,"status":"aborted","timestamp":1680618681275,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"5df02e6a","scrolled":true},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"8d938d26","metadata":{"executionInfo":{"elapsed":70,"status":"aborted","timestamp":1680618681275,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"8d938d26"},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"4fc3105a","metadata":{"executionInfo":{"elapsed":71,"status":"aborted","timestamp":1680618681276,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"4fc3105a","scrolled":false},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"d320cca0","metadata":{"id":"d320cca0"},"source":["<hr>\n","\n","### Model Evaluation 5\n","\n","##### Variables Used : \n","Based fully on RFECV\n","<br>\n","Selected Num Features: 8 - ['HighBP', 'HighChol', 'GenHlth', 'Sex', 'Age', 'Education', 'Income',\n","       'BMI_bins']"]},{"cell_type":"code","execution_count":null,"id":"69708810","metadata":{"executionInfo":{"elapsed":70,"status":"aborted","timestamp":1680618681276,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"69708810"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'HighChol', 'GenHlth', 'Sex', 'Age', 'Education', 'Income',\n","       'BMI_bins']\n","\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"32d1ed94","metadata":{"executionInfo":{"elapsed":71,"status":"aborted","timestamp":1680618681277,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"32d1ed94"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n","\n","\n","# Create adaboost model object\n","\n","adaboost_model = AdaBoostClassifier()\n","\n","\n","# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n","\n","plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n"]},{"cell_type":"markdown","id":"dcc465b7","metadata":{"id":"dcc465b7"},"source":["##### Average AUC-ROC Curve of all folds"]},{"cell_type":"code","execution_count":null,"id":"5e79a6e9","metadata":{"executionInfo":{"elapsed":71,"status":"aborted","timestamp":1680618681277,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"5e79a6e9","scrolled":true},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"8b212bf0","metadata":{"executionInfo":{"elapsed":71,"status":"aborted","timestamp":1680618681278,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"8b212bf0","scrolled":true},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"cb5b113f","metadata":{"executionInfo":{"elapsed":75,"status":"aborted","timestamp":1680618681282,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"cb5b113f","scrolled":false},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"04607d7e","metadata":{"id":"04607d7e"},"source":["<hr>\n","\n","### Model Evaluation 6\n","\n","##### Variables Used : \n","Based fully on RFECV\n","<br>\n","Selected Num Features: 18 - ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke',\n","       'HeartDiseaseorAttack', 'PhysActivity', 'Veggies', 'HvyAlcoholConsump',\n","       'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age',\n","       'Education', 'Income', 'BMI_bins']"]},{"cell_type":"code","execution_count":null,"id":"67636599","metadata":{"executionInfo":{"elapsed":75,"status":"aborted","timestamp":1680618681282,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"67636599"},"outputs":[],"source":["# can tweak the features as needed\n","features = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke',\n","       'HeartDiseaseorAttack', 'PhysActivity', 'Veggies', 'HvyAlcoholConsump',\n","       'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age',\n","       'Education', 'Income', 'BMI_bins']\n","\n","X = train_test_data[features]\n","y = train_test_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"da4d1b5c","metadata":{"executionInfo":{"elapsed":75,"status":"aborted","timestamp":1680618681283,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"da4d1b5c"},"outputs":[],"source":["# Create K-Fold splitter for 10 folds\n","num_of_folds = 10\n","skf = StratifiedKFold(n_splits=num_of_folds, shuffle=True, random_state=424)\n","\n","\n","# Create adaboost model object\n","\n","adaboost_model = AdaBoostClassifier()\n","\n","\n","# List of accuracy for each fold\n","k_fold_accuracy = []\n","k_fold_classification_error = []\n","k_fold_sensitivity = []\n","k_fold_precision = []\n","k_fold_specificity = []\n","k_fold_f1_score = []\n","\n","auc_roc_scores = []\n","fpr_values = []\n","tpr_values = []\n","\n","plt.figure(figsize=(10, 10))\n","# Iterate through each fold and calculate the accuracy for each fold\n","fold = 1\n","\n","for train_index, test_index in skf.split(X,y):\n","    \n","    # Extract the training and test data\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Fit/predict on train/validation set\n","    y_pred = adaboost_model.fit(X_train, y_train).predict(X_test)\n","    # -----------------------------------------------------------\n","    \n","    #confusion Matrix\n","    confusion = metrics.confusion_matrix(y_test, y_pred)\n","    \n","    # Access specific values of confusion matix using [row, column]\n","    TN = confusion[0, 0]\n","    FP = confusion[0, 1]\n","    FN = confusion[1, 0]\n","    TP = confusion[1, 1]\n","    \n","    \n","    # Calculate accuracy for the fold and append it\n","    accuracy = metrics.accuracy_score(y_test, y_pred)\n","    k_fold_accuracy.append(round(accuracy, 4))\n","    #print('The accuracy for each fold is:', k_fold_accuracy)\n","    \n","    # Calculate classification error derived from accuracy (we minus it against 1) for the fold and append it\n","    classification_error = 1 - accuracy\n","    k_fold_classification_error.append(round(classification_error, 4))\n","\n","    # Calculate sensitivity for the fold and append it\n","    sensitivity = metrics.recall_score(y_test, y_pred)\n","    k_fold_sensitivity.append(round(sensitivity, 4))\n","\n","    # Calculate precision for the fold and append it\n","    precision = metrics.precision_score(y_test, y_pred)\n","    k_fold_precision.append(round(precision, 4))\n","    \n","    # Calculate specificity for the fold and append it\n","    specificity = TN / (TN + FP)\n","    k_fold_specificity.append(round(specificity, 4))\n","    \n","    # Calculate f1_score for the fold and append it\n","    f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","    k_fold_f1_score.append(round(f1_score, 4))\n","    \n","    #--------------------------------------------------------------------------------------------------\n","    \n","    y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n","\n","    \n","    # Calculate the AUC-ROC score for this fold\n","    auc_roc_score = roc_auc_score(y_test, y_pred_proba)\n","    auc_roc_scores.append(auc_roc_score)\n","\n","    # Calculate the fpr/tpr values for the ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    fpr_values.append(fpr)\n","    tpr_values.append(tpr)\n","    \n","    \n","    plt.plot(fpr, tpr, label=f\"ROC curve for fold {fold}\")    \n","\n","    fold += 1\n","    \n","print(len(auc_roc_scores))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n"]},{"cell_type":"markdown","id":"5a4f3244","metadata":{"id":"5a4f3244"},"source":["##### Average AUC-ROC Curve of all folds"]},{"cell_type":"code","execution_count":null,"id":"060b428a","metadata":{"executionInfo":{"elapsed":75,"status":"aborted","timestamp":1680618681283,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"060b428a","scrolled":true},"outputs":[],"source":["# Calculate the (1) average false positive rate, (2) average true positive rate\n","\n","# Get the maximum length of the arrays in the list\n","max_length_fpr = max(len(a) for a in fpr_values)\n","max_length_tpr = max(len(a) for a in tpr_values)\n","\n","# Pad each array in the list with zeros so that they have the same length\n","padded_fpr = np.array([np.pad(a, (0, max_length_fpr - len(a)), mode='constant') for a in fpr_values])\n","padded_tpr = np.array([np.pad(a, (0, max_length_tpr - len(a)), mode='constant') for a in tpr_values])\n","\n","weights = [len(test_index) / len(y) for _, test_index in skf.split(X,y)]\n","avg_auc_roc = np.average(auc_roc_scores, weights=weights, axis=0)\n","avg_fpr_value = np.average(padded_fpr, weights=weights, axis=0)\n","avg_tpr_value = np.average(padded_tpr, weights=weights, axis=0)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x = avg_fpr_value, y = avg_tpr_value,\n","    title = f'ROC Curve (AUC={avg_auc_roc:.4f})',\n","    labels = dict(x = 'Average False Positive Rate', y = 'Average True Positive Rate'),\n","    width = 700, height = 700\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"e16affc3","metadata":{"executionInfo":{"elapsed":76,"status":"aborted","timestamp":1680618681284,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"e16affc3","scrolled":true},"outputs":[],"source":["x_axis = [i for i in range(1, num_of_folds + 1)]\n","fig = px.scatter( x = x_axis, y = auc_roc_scores,\n","                 labels = {\"x\": \"K-Fold\", \"y\": \"AUC Score\"},\n","                 trendline = 'ols',\n","                 title = 'AUC Values for the the each K-Fold' # add title parameter\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"9cc92431","metadata":{"executionInfo":{"elapsed":76,"status":"aborted","timestamp":1680618681284,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"9cc92431","scrolled":false},"outputs":[],"source":["print('The average accuracy is:', statistics.mean(k_fold_accuracy))\n","print('The average classification error is:', statistics.mean(k_fold_classification_error))\n","print('The average sensitivity is:', statistics.mean(k_fold_sensitivity))\n","print('The average precision is:', statistics.mean(k_fold_precision))\n","print('The average specificity is:', statistics.mean(k_fold_specificity))\n","print('The average f1 score is:', statistics.mean(k_fold_f1_score))\n"]},{"cell_type":"markdown","id":"8eb9708e","metadata":{"id":"8eb9708e"},"source":["<hr>\n","<hr>\n","\n","## Hyper Parameter Tuning based on precision\n","- Hyper parameter is done using Random Search CV which finds the best permutation of params within 40 iterations\n","- Random search cv is used as it provides a balance between quality and computation time\n","- <b>Validaton data set</b> is used to find the Best Parameters"]},{"cell_type":"code","execution_count":null,"id":"f1c23e22","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681285,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"f1c23e22"},"outputs":[],"source":["# Best Features \n","features =['HighBP','HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack','PhysActivity','Veggies','HvyAlcoholConsump','GenHlth','MentHlth','PhysHlth','DiffWalk','Sex','Age','Education','Income','BMI_bins'] #input best features\n","X = val_data[features]\n","y = val_data[\"Diabetes_binary\"]"]},{"cell_type":"code","execution_count":null,"id":"3bd15d9b","metadata":{"executionInfo":{"elapsed":76,"status":"aborted","timestamp":1680618681285,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"3bd15d9b"},"outputs":[],"source":["# Define the hyperparameter space\n","params = {\n","    'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400],\n","    'learning_rate': [0.1,0.2,0.3,0.4,0.5],\n","}"]},{"cell_type":"code","execution_count":null,"id":"130b8ada","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681286,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"130b8ada"},"outputs":[],"source":["# Create a CatBoost Classifier model\n","model = AdaBoostClassifier()\n","\n","# Define the Random Search CV object\n","random_search = RandomizedSearchCV(\n","    model, \n","    param_distributions=params, \n","    n_iter=40, \n","    cv=5,\n","    random_state=424\n",")"]},{"cell_type":"code","execution_count":null,"id":"67879352","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681286,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"67879352"},"outputs":[],"source":["# Fit the Random Search CV object to the data\n","random_search.fit(X, y)\n","\n","# Print the best hyperparameters and the corresponding score\n","print('Best Hyperparameters:', random_search.best_params_)\n","print('Best Score:', random_search.best_score_)"]},{"cell_type":"markdown","id":"27b37b2b","metadata":{"id":"27b37b2b"},"source":["<hr>\n","<hr>\n","<hr>"]},{"cell_type":"markdown","id":"e4ec3b60","metadata":{"id":"e4ec3b60"},"source":["## Model Evaluation using Best Features and Best Params on Unseen data based on sensitivity and precision"]},{"cell_type":"code","execution_count":null,"id":"65062f3a","metadata":{"executionInfo":{"elapsed":76,"status":"aborted","timestamp":1680618681286,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"65062f3a"},"outputs":[],"source":["# Best Features \n","features = ['HighBP','HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack','PhysActivity','Veggies','HvyAlcoholConsump','GenHlth','MentHlth','PhysHlth','DiffWalk','Sex','Age','Education','Income','BMI_bins'] #input best variables\n","X = train_test_data[features] #model training\n","y = train_test_data[\"Diabetes_binary\"] #model training\n","\n","X_unseen = unseen_data[features] #test final model on this\n","y_unseen = unseen_data[\"Diabetes_binary\"] #test final model on this\n","  \n","# Final Model with best params\n","final_model = AdaBoostClassifier(n_estimators=350, learning_rate=0.2)"]},{"cell_type":"code","execution_count":null,"id":"9e7aa83e","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681287,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"9e7aa83e"},"outputs":[],"source":["plt.figure(figsize=(6, 6))\n","\n","# Fit/predict on unseen data set\n","y_pred = final_model.fit(X, y).predict(X_unseen)\n","# -----------------------------------------------------------\n","\n","#confusion Matrix\n","confusion = metrics.confusion_matrix(y_unseen, y_pred)\n","\n","# Access specific values of confusion matix using [row, column]\n","TN = confusion[0, 0]\n","FP = confusion[0, 1]\n","FN = confusion[1, 0]\n","TP = confusion[1, 1]\n","\n","\n","# Calculate accuracy \n","accuracy = metrics.accuracy_score(y_unseen, y_pred)\n","\n","# Calculate classification error derived from accuracy (we minus it against 1) \n","classification_error = 1 - accuracy\n","\n","# Calculate sensitivity \n","sensitivity = metrics.recall_score(y_unseen, y_pred)\n","\n","# Calculate precision \n","precision = metrics.precision_score(y_unseen, y_pred)\n","\n","# Calculate specificity \n","specificity = TN / (TN + FP)\n","\n","# Calculate f1_score\n","f1_score = (2 * sensitivity * precision) / (sensitivity + precision)\n","\n","#--------------------------------------------------------------------------------------------------\n","\n","y_pred_proba = final_model.predict_proba(X_unseen)[:, 1]\n","\n","\n","# Calculate the AUC-ROC score\n","auc_roc_score = roc_auc_score(y_unseen, y_pred_proba)\n","\n","\n","# Calculate the fpr/tpr values for the ROC curve\n","fpr, tpr, _ = roc_curve(y_unseen, y_pred_proba)\n"]},{"cell_type":"code","execution_count":null,"id":"7a4ff6e5","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681287,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"7a4ff6e5","scrolled":true},"outputs":[],"source":["auc_value = metrics.auc(fpr, tpr)\n","\n","# Plot AUC using area chart\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc_value:.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=700, height=500\n",")\n","\n","# This part adds formatting & plots the dashed line at AUC=0.5 \n","fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"id":"761f56ae","metadata":{"executionInfo":{"elapsed":77,"status":"aborted","timestamp":1680618681288,"user":{"displayName":"ABHISIT ANUPAPPHAN _","userId":"05313850060777099862"},"user_tz":-480},"id":"761f56ae"},"outputs":[],"source":["print('The accuracy on unseen data is: ', accuracy)\n","print('The classification_error on unseen data is: ', classification_error)\n","print('The sensitivity on unseen data is: ', sensitivity)\n","print('The precision on unseen data is: ', precision)\n","print('The specificity on unseen data is: ', specificity)\n","print('The f1_score on unseen data is: ', f1_score)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
